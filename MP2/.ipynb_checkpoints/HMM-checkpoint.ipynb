{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import multivariate_normal as mvn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEA_WP = pd.read_pickle('./work_shared/fea_word_person.pkl') # speaker dependent features\n",
    "FEA_PW = pd.read_pickle('./work_shared/fea_person_word.pkl') # speaker independent features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning the parameters of HMM\n",
    "class Gaussian_HMM:\n",
    "    def __init__(self, train_data, init_pi, init_A, K = 5, epoch = 10):\n",
    "        self.train_data = train_data\n",
    "        self.L = len(train_data)\n",
    "        self.state = K\n",
    "        self.pi = init_pi\n",
    "        self.A = init_A\n",
    "        self.mean = np.array([np.mean(np.vstack(train_data), axis = 0)] * K)\n",
    "        self.cov = np.array([np.cov(np.vstack(train_data), rowvar = False)] * K)\n",
    "        self.epoch = epoch\n",
    "    \n",
    "    def find_emission(self, x):\n",
    "        T = x.shape[0]\n",
    "        b = np.zeros((x.shape[0], self.state))\n",
    "        \n",
    "        for t in range(T):\n",
    "            for k in range(self.state):\n",
    "                b[t,k] = mvn.pdf(x[t],self.mean[k],self.cov[k],allow_singular = True)\n",
    "                \n",
    "        return b\n",
    "    \n",
    "    def forward(self, x, b):\n",
    "        T = x.shape[0]\n",
    "        alpha = np.zeros((T, self.state))\n",
    "        g = np.zeros(T) # scaling factors\n",
    "        alpha[0,:] = self.pi * b[0,:]\n",
    "        g[0] = np.sum(alpha[0,:])\n",
    "        alpha[0,:] = alpha[0,:] / g[0]\n",
    "        \n",
    "        for t in range(1,T):\n",
    "            alpha_prev = np.dot(alpha[t-1].reshape(1,-1), self.A)\n",
    "            alpha[t,:] = alpha_prev * b[t]\n",
    "            g[t] = np.sum(alpha[t])\n",
    "            alpha[t] = alpha[t] / g[t]\n",
    "            \n",
    "        return alpha, g\n",
    "    \n",
    "    def backward(self, x, b, g):\n",
    "        T = x.shape[0]\n",
    "        beta = np.zeros((T, self.state))\n",
    "        beta[T-1, :] = np.ones(self.state)\n",
    "        \n",
    "        for t in reversed(range(T-1)):\n",
    "            beta_next = beta[t+1] * b[t+1]\n",
    "            beta[t] = np.dot(beta_next.reshape(1,-1),self.A.T)\n",
    "            beta[t] = beta[t,:] / g[t+1]\n",
    "\n",
    "        return beta\n",
    "    \n",
    "    def find_xi(self, x, b, g, alpha, beta):\n",
    "        T = x.shape[0]\n",
    "        xi = np.zeros((T-1, self.state, self.state))    \n",
    "        \n",
    "        for t in range(T-1):\n",
    "            beta_next = beta[t+1] *  b[t+1]\n",
    "            xi[t] = np.dot(alpha[t,:].reshape(-1,1),beta_next.reshape(1,-1))\n",
    "            xi[t] =  xi[t] * self.A\n",
    "            xi[t] =  xi[t]/ g[t+1] \n",
    "            \n",
    "        return xi\n",
    "        \n",
    "    def find_gamma(self, alpha, beta):\n",
    "        gamma = alpha * beta\n",
    "        return gamma\n",
    "    \n",
    "    def train_model(self):    \n",
    "        for it in range(self.epoch):\n",
    "            print(\"Current iteration: \",it)\n",
    "            alpha = []\n",
    "            beta = []\n",
    "            g = []\n",
    "            xi = []\n",
    "            gamma = []\n",
    "\n",
    "            # E step\n",
    "            for l in range(self.L):\n",
    "                x = self.train_data[l]\n",
    "                b = self.find_emission(x)\n",
    "                cur_alpha,cur_g = self.forward(x, b)\n",
    "                cur_beta = self.backward(x, b, cur_g)\n",
    "                cur_xi = self.find_xi(x, b, cur_g, cur_alpha, cur_beta)\n",
    "                cur_gamma = self.find_gamma(cur_alpha, cur_beta)\n",
    "\n",
    "                alpha.append(cur_alpha)\n",
    "                beta.append(cur_beta)\n",
    "                g.append(cur_g)\n",
    "                xi.append(cur_xi)\n",
    "                gamma.append(cur_gamma)\n",
    "\n",
    "            # M step\n",
    "            # re-estimates pi\n",
    "            for l in range(self.L):\n",
    "                cur_gamma = gamma[l]\n",
    "                self.pi  += cur_gamma[0]\n",
    "            self.pi = self.pi / np.sum(self.pi)\n",
    "\n",
    "            # re-estimate transition matrix  \n",
    "            for l in range(self.L):\n",
    "                cur_xi = xi[l]\n",
    "                self.A += np.sum(cur_xi, axis = 0)\n",
    "            self.A = self.A / np.sum(self.A, axis = 1, keepdims= True)\n",
    "\n",
    "            # re-estimates means\n",
    "            denom = np.zeros((self.state,1))\n",
    "            num = np.zeros(self.mean.shape)\n",
    "            for l in range(self.L):\n",
    "                cur_gamma = gamma[l]\n",
    "                x = self.train_data[l]\n",
    "                denom += np.sum(cur_gamma, axis = 0).reshape(self.state,1)\n",
    "                num += np.matmul(cur_gamma.T, x)\n",
    "            self.mean = num/denom\n",
    "\n",
    "            # re-estimates covariances\n",
    "#             for l in range(self.L):\n",
    "#                 cur_gamma = gamma[l]\n",
    "#                 x = self.train_data[l]\n",
    "#                 for k in range(self.state):\n",
    "#                     denom = 0\n",
    "#                     num = 0\n",
    "#                     for t in range(x.shape[0]):\n",
    "#                         denom += cur_gamma[t,k]\n",
    "#                         num += cur_gamma[t,k] * np.dot((x[t] - self.mean[k]).reshape(-1,1), (x[t] - self.mean[k]).reshape(1,-1))\n",
    "#                 self.cov[k] = num/denom\n",
    "            denom = np.zeros((self.state, 1))\n",
    "            num = np.zeros(self.cov.shape)\n",
    "            for l in range(self.L):\n",
    "                cur_gamma = gamma[l]\n",
    "                x = self.train_data[l]\n",
    "                denom += np.sum(cur_gamma, axis = 0).reshape(self.state,1)\n",
    "                for k in range(self.state):\n",
    "                    for t in range(x.shape[0]):\n",
    "                        num[k] += cur_gamma[t,k] * np.dot((x[t] - self.mean[k]).reshape(-1,1), (x[t] - self.mean[k]).reshape(1,-1))\n",
    "                self.cov[k] = num[k]/denom[k]\n",
    "        return self.pi, self.A, self.mean, self.cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_pi = np.array([1/5] * 5)\n",
    "\n",
    "init_A = np.array([[.8, .2,   0,   0,   0],\n",
    "              [0,  .8,  .2,   0,   0],\n",
    "              [0,   0,  .8,  .2,   0],\n",
    "              [0,   0,   0,  .8,  .2],\n",
    "              [0,   0,   0,   0,   1]])\n",
    "\n",
    "words = ['cnn', 'dnn', 'asr', 'tts', 'hmm']\n",
    "speakers = ['mh', 'ls', 'dg', 'yx']\n",
    "num_words = 5\n",
    "num_speakers = 4\n",
    "num_utterances = 5\n",
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "for w in range(num_words):\n",
    "    train_word_data = []\n",
    "    test_word_data = []\n",
    "    word = words[w]\n",
    "    for s in range(num_speakers):\n",
    "        speaker = speakers[s]\n",
    "        for u in range(num_utterances):\n",
    "            if u != (num_utterances - 1):\n",
    "                train_word_data.append(FEA_WP[word][speaker][u])\n",
    "            else:\n",
    "                test_word_data.append(FEA_WP[word][speaker][u])\n",
    "    train_data.append(np.array(train_word_data))\n",
    "    test_data.append(np.array(test_word_data))\n",
    "    \n",
    "cnn_model = Gaussian_HMM(train_data[0], init_pi, init_A)\n",
    "dnn_model = Gaussian_HMM(train_data[1], init_pi, init_A)\n",
    "asr_model = Gaussian_HMM(train_data[2], init_pi, init_A)\n",
    "tts_model = Gaussian_HMM(train_data[3], init_pi, init_A)\n",
    "hmm_model = Gaussian_HMM(train_data[4], init_pi, init_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration:  0\n",
      "Current iteration:  1\n",
      "Current iteration:  2\n",
      "Current iteration:  3\n",
      "Current iteration:  4\n",
      "Current iteration:  5\n",
      "Current iteration:  6\n",
      "Current iteration:  7\n",
      "Current iteration:  8\n",
      "Current iteration:  9\n"
     ]
    }
   ],
   "source": [
    "cnn_pi, cnn_A, cnn_mean, cnn_cov = cnn_model.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration:  0\n",
      "Current iteration:  1\n",
      "Current iteration:  2\n",
      "Current iteration:  3\n",
      "Current iteration:  4\n",
      "Current iteration:  5\n",
      "Current iteration:  6\n",
      "Current iteration:  7\n",
      "Current iteration:  8\n",
      "Current iteration:  9\n"
     ]
    }
   ],
   "source": [
    "dnn_pi, dnn_A, dnn_mean, dnn_cov = dnn_model.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration:  0\n",
      "Current iteration:  1\n",
      "Current iteration:  2\n",
      "Current iteration:  3\n",
      "Current iteration:  4\n",
      "Current iteration:  5\n",
      "Current iteration:  6\n",
      "Current iteration:  7\n",
      "Current iteration:  8\n",
      "Current iteration:  9\n"
     ]
    }
   ],
   "source": [
    "asr_pi, asr_A, asr_mean, asr_cov = asr_model.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration:  0\n",
      "Current iteration:  1\n",
      "Current iteration:  2\n",
      "Current iteration:  3\n",
      "Current iteration:  4\n",
      "Current iteration:  5\n",
      "Current iteration:  6\n",
      "Current iteration:  7\n",
      "Current iteration:  8\n",
      "Current iteration:  9\n"
     ]
    }
   ],
   "source": [
    "tts_pi, tts_A, tts_mean, tts_cov = tts_model.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration:  0\n",
      "Current iteration:  1\n",
      "Current iteration:  2\n",
      "Current iteration:  3\n",
      "Current iteration:  4\n",
      "Current iteration:  5\n",
      "Current iteration:  6\n",
      "Current iteration:  7\n",
      "Current iteration:  8\n",
      "Current iteration:  9\n"
     ]
    }
   ],
   "source": [
    "hmm_pi, hmm_A, hmm_mean, hmm_cov = hmm_model.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_predict(x, K, pi, A, mean, cov):\n",
    "    T = x.shape[0]\n",
    "    b = np.zeros((x.shape[0],K))\n",
    "    for t in range(x.shape[0]):\n",
    "        for k in range(K):\n",
    "            b[t,k] = mvn.pdf(x[t], mean[k], cov[k], allow_singular=True)\n",
    "\n",
    "    alpha = np.zeros((T,K))\n",
    "    c = np.zeros(T)\n",
    "    for i in range(K):\n",
    "        alpha[0,i] = pi[i] * mvn.pdf(x[0], mean[i], cov[i], allow_singular=True)\n",
    "    c[0] = np.sum(alpha[0])\n",
    "    alpha[0] = alpha[0] / c[0]\n",
    "    for t in range(1,T):\n",
    "        alpha[t] = np.dot(alpha[t-1].reshape(1,-1), A)\n",
    "        alpha[t] = alpha[t] * b[t]\n",
    "        c[t] = np.sum(alpha[t])\n",
    "        alpha[t] = alpha[t] / c[t]\n",
    "        \n",
    "    return np.sum(np.log(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = np.zeros((5,5))\n",
    "for w in range(len(test_data)):\n",
    "    word_data = test_data[w]\n",
    "    for l in range(len(word_data)):\n",
    "        x = word_data[l]\n",
    "        cnn_prob = forward_predict(x, 5, cnn_pi, cnn_A, cnn_mean, cnn_cov)\n",
    "        dnn_prob = forward_predict(x, 5, dnn_pi, dnn_A, dnn_mean, dnn_cov)\n",
    "        asr_prob = forward_predict(x, 5, asr_pi, asr_A, asr_mean, asr_cov)\n",
    "        tts_prob = forward_predict(x, 5, tts_pi, tts_A, tts_mean, tts_cov)\n",
    "        hmm_prob = forward_predict(x, 5, hmm_pi, hmm_A, hmm_mean, hmm_cov)\n",
    "        prob = np.array([cnn_prob, dnn_prob, asr_prob, tts_prob, hmm_prob])\n",
    "        confusion_matrix[w, np.argmax(prob)]+=1\n",
    "confusion_matrix /= 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.   0.   0.   0.   0.  ]\n",
      " [0.25 0.75 0.   0.   0.  ]\n",
      " [0.   0.   1.   0.   0.  ]\n",
      " [0.   0.   0.   1.   0.  ]\n",
      " [0.   0.   0.   0.   1.  ]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
